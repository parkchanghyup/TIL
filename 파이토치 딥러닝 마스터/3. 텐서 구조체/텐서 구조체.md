## 부동소수점 수의 세계

심층 신경망은 보통 여러 단계를 거쳐 데이터 변환을 학습한다. 그래서 각 단계 사이의 일부 변환된 데이터들은 중간 단계를 표현하는 연속적인 흐름으로 생각할 수 있다.  

이미지 인식의 경우 앞 단계에서 모서리를 검출하거나 털 같은 질감을 잡아내고 깊이 들어갈수록 귀나 코 혹은 눈 같은 복잡한 구조를 파악한다.  

일반적으로 이러한 중간 단계는 입력값의 특징을 잡아내는 부동소수점 수의 모음인 동시에 신경망에서 입력이 최종적으로 출력으로 표현되는 방법을 기술하기 위한 수단으로 데이터 구조를 잡아낸다.  

데이터를 부동소수점 입력으로 바꾸기 전에 먼저, 파이토치가 입력과 중간 표현 그리고 출력으로서 어떻게 데이터를 다루고 저장하는지 잘 이해할 필요가 있다.  

데이터 처리와 저장을 위해 파이토치에서는 `텐서`라는 기본 자료구조를 제공한다.  딥러닝에서의 텐서는 아래 그림에서 보는 것과 같은 임의의 차원을 가진 벡터나 행렬의 일반화된 개념으로 생각하면 된다.  

텐서의 차원 수는 텐서 안의 스칼라 값을 참조하기 위해 사용하는 인덱스 수와 동일하다.  

![](img/img1.jpeg)    

## 텐서 : 다차원 배열
텐서는 일종의 배열이다. 즉 한 개나 여러 개의 인덱스를 사용해 개별적으로 값에 접근할 수 있는 형태의 숫자 모음을 저장하는 자료구조이다.  

### 텐서의 핵심
숫자값으로 만든 파이썬 리스트나 튜플 객체는 아래 왼쪽 그림처럼 메모리에 따로따로 할당된다.  
반면 파이토치 텐서나 넘파이 배열은 파이썬 객체가 아닌 `언박싱(unboxing)`된 C 언어 숫자 타입을 포함한 연속적인 메모리가 할당되고 이에 대한 뷰를 제공한다.  
여기서 각 요소는 32비트 float 타입이며 오른쪽 그림에서 볼 수 있다. 100만 개의 float 타입 숫자를 1차원 텐서에 보관한다면 400만 바이트의 연속적인 공간과 (차원이나 숫자 타입을 기록하는 용도) 메타데이터 공간을 조금 더 차지한다.  

![](img/img1.jpeg)    

### 텐서 인덱싱
만일 모든 포인트에서 첫 번째 값만 구해야 한다면? 다음처럼 표준 파이썬과 마찬가지로 범위 인덱싱을 사용한다. 
```python
tensor[1:] # 첫 번째 이후 모든 행에 대해.
tensor[1:,:] # 첫 번째 이후 모든 행에 대해
tensor[1:, 0] # 첫 번째 이후 모든 행에 대해 첫 번째 열만 포함
tensor[None] # 길이가 1인 차원을 추가함. unsqueeze와 동일
```


## 이름이 있는 텐서
우리가 다루는 텐서는 차원이나 축이 있으며, 각 차원은 픽셀 위치나 컬러 채널에 해당한다. 때문에 텐서를 접근하려면 차원의 순서를 기억해서 인덱싱해야 한다.  
데이터가 여러 텐서 형태를 거치며 다양하게 변환되면, 어느 차원에 어떤 데이터가 들어있는지 헷갈려 실수하기 쉽다.  

```python
img_t = torch.randn(3, 5, 5) # 각각이 [채널, 행, 열]이 됨.
weights = torch.tensor([0.1234, 0.5942, 0.0439])
```
이런 코드는 일반화 하면 좋다. 예를 들어 높이와 너비를 가진 2차원 텐서로 이뤄진 흑백이미지로부터 RGB값을 담을 세 번째 채널 차원을 더하는 코드로 만드는 것이다. 아니면 개별 이미지 여러 개를 묶어 배치로 만드는 코드를 생각할 수 있다. 배치 크기 2로 바꿔보다

```python
batch = torch.randn(2, 3, 5, 5) # [배치, 채널, 행, 열]
```

경우에 따라 RGB채널은 0 번 혹은 1번 차원에 있다. 두 경우 모드 뒤에서부터 세 번째 차원이므로 RGB 채널은 -3번 차원에 있는 것으로 일반화 할 수 있다. 이러면 다음 코드로 배치 차원 유무에 상관없이 평균을 구할 수 있따.


