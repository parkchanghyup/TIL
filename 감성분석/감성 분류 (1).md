# 강남역 맛집 리뷰로 알아보는 감성 분류
---



```python
# -*- coding: utf-8 -*-

%matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")
```


```python
'''
크롤링 과정 생략 .. 
'''
df = pd.read_csv("review_data.csv")
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
      <th>review</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>친절하시고 깔끔하고 좋았습니다</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>조용하고 고기도 굿</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>갈비탕과 냉면, 육회비빔밥이 맛있습니다.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>대체적으로 만족하나\r\n와인의 구성이 살짝 아쉬움</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>고기도 맛있고 서비스는 더 최고입니다~</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>540</th>
      <td>3</td>
      <td>추웟어요 고기 외에는 별로에요..</td>
      <td>0</td>
    </tr>
    <tr>
      <th>541</th>
      <td>1</td>
      <td>고기질과 육전은 좋다.다만 한우손님 돼지고기 손님을 차별한다(돼지손님은 주차불가.네...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>542</th>
      <td>5</td>
      <td>직접 구워주시고 진짜맛있음. 반찬도 맛있음. 직원분이 친절하게 잘해주시네요</td>
      <td>1</td>
    </tr>
    <tr>
      <th>543</th>
      <td>4</td>
      <td>친절하게 서빙해주시고 음식도 챙겨주셨어요 ㅎ</td>
      <td>1</td>
    </tr>
    <tr>
      <th>544</th>
      <td>4</td>
      <td>강남역 점례네 방문\r\n육회비빔밥은 맛있었당\r\n뼈삼겹도 맛있었다\r\n\r\n...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>545 rows × 3 columns</p>
</div>



## TF-IDF 를 이용한 핵심어 추출
---

### 형태소 추출
---
- 한글 텍스트로 전처리


```python
import re

# 텍스트 정제 함수
def text_cleaning(text):
    #한글의 정규표현식으로 한글만 추출
    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')
    result = hangul.sub('',text)
    return result
```


```python
# 함수를 적용하여 리뷰에서 한글만 추출

df['ko_text'] = df['review'].apply(lambda x : text_cleaning(x))
del df['review']
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
      <th>y</th>
      <th>ko_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>1</td>
      <td>친절하시고 깔끔하고 좋았습니다</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>1</td>
      <td>조용하고 고기도 굿</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>1</td>
      <td>갈비탕과 냉면 육회비빔밥이 맛있습니다</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>대체적으로 만족하나와인의 구성이 살짝 아쉬움</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>1</td>
      <td>고기도 맛있고 서비스는 더 최고입니다</td>
    </tr>
  </tbody>
</table>
</div>



### 형태소 단위로 추출


```python
from konlpy.tag import Okt

#konlpy 라이브러리로 텍스트 데이터에서 형태소를 추출.

def get_pos(x):
    tagger = Okt()
    pos = tagger.pos(x)
    pos = ['{}/{}'.format(word,tag) for word, tag in pos]
    return pos

# 형태소 추출 동작을 테스트
result = get_pos(df['ko_text'][0])
print(result)
```

    ['친절하시고/Adjective', '깔끔하고/Adjective', '좋았습니다/Adjective']
    

## 분류 모델의 학습 데이터로 변환

### corpus index 생성하기


```python
from sklearn.feature_extraction.text import CountVectorizer

# 형태소를 벡터 형태의 학습 데이터셋 으로 변환합니다.
index_vectorizer = CountVectorizer(tokenizer = lambda x : get_pos(x))
X = index_vectorizer. fit_transform(df['ko_text'].tolist())

```


```python
X.shape
```




    (545, 3030)




```python
print(str(index_vectorizer.vocabulary_)[:100]+"..")
```

    {'친절하시고/Adjective': 2647, '깔끔하고/Adjective': 428, '좋았습니다/Adjective': 2403, '조용하고/Adjective': 2356, '고..
    


```python
print(df['ko_text'][0])
print(X[0])
```

    친절하시고 깔끔하고 좋았습니다
      (0, 2647)	1
      (0, 428)	1
      (0, 2403)	1
    

## TF-IDF로 변환
--- 
TF_IDF는 단어 빈도를 나타내는 TF와 문서 빈도를 나타내는 DF의 역수인 IDF를 곱한 값을 의미. 만약 1번 텍스트에 '맛집'이라는 단어가 3번 등장하고, 모든 데이터에서는 '맛집'이라는 단어가 10개 의 텍스트에 등장한다고 할때, 1번 문서에서 '맛집의 TF값은 3, IDF값은 0.1이 된다.  


따라서 TF-IDF는 다른 문서들에서는 등장하지 않았지만 현재 문서에서는 많이 등장하는 단어를 의미하며, 그 단어가 현재 문서에서 얼마나 중요한지를 피처로 나타낼 수 있는 방법이다.


```python
from sklearn.feature_extraction.text import TfidfTransformer

# TF-IDF 방법으로, 형태소를 벡터 형태의 학습 데이터셋으로 변환
tfidf_vectorizer = TfidfTransformer()
X = tfidf_vectorizer.fit_transform(X)
```


```python
print(X.shape)
print(X[0])
```

    (545, 3030)
      (0, 2647)	0.5548708693511647
      (0, 2403)	0.48955631270748484
      (0, 428)	0.6726462183300624
    
